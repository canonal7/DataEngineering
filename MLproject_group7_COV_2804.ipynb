{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting medical no-shows with COV\n",
    "ML Project (group 7): Continuous variables (COV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting global random seed (necessary for sklearn models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"KaggleV2-May-2016.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n",
    "df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\n",
    "df['Gender'] = df['Gender'].map({'F': True, 'M': False})\n",
    "df['No-show'] = df['No-show'].map({'Yes': True, 'No': False})\n",
    "df['Scholarship'] = df['Scholarship'].astype(bool)\n",
    "df['Diabetes'] = df['Diabetes'].astype(bool)\n",
    "df['Hipertension'] = df['Hipertension'].astype(bool)\n",
    "df['Alcoholism'] = df['Alcoholism'].astype(bool)\n",
    "df['SMS_received'] = df['SMS_received'].astype(bool)\n",
    "df['handicap_boolean'] = df['Handcap'].replace([2, 3, 4], 1).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['only_date_appointment_day'] = df['AppointmentDay'].dt.date\n",
    "df['only_date_scheduled_day'] = df['ScheduledDay'].dt.date\n",
    "df['lead_days'] = (df['only_date_appointment_day'] - df['only_date_scheduled_day']).dt.days.astype(np.int64)\n",
    "df = df.drop('only_date_appointment_day', axis = 1)\n",
    "df = df.drop('only_date_scheduled_day', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[df['Age'] >= 0]\n",
    "df = df[df['Age'] <= 100]\n",
    "df = df[df['lead_days'] >= 0]\n",
    "df = df[df['lead_days'] != 398]\n",
    "df = df.drop('SMS_received', axis = 1)\n",
    "df = df.drop('Neighbourhood', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating train/test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_cov = ['Gender', 'Age', 'Scholarship', 'Hipertension','Diabetes', 'Alcoholism','lead_days', 'handicap_boolean']\n",
    "target = 'No-show'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[predictors_cov], df[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(random_state=42, categorical_features = [True])\n",
    "X_train_smote_cov, y_train_smote_cov = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Original dataset shape')\n",
    "print('False:', sum(y_train == False))\n",
    "print('True: ', sum(y_train == True))\n",
    "print('Resampled dataset COV shape with SMOTE')\n",
    "print('False:', sum(y_train_smote_cov == False))\n",
    "print('True: ', sum(y_train_smote_cov == True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling - duplicating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros_cov, y_train_ros_cov = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Original dataset shape')\n",
    "print('False:', sum(y_train == False))\n",
    "print('True: ', sum(y_train == True))\n",
    "print('Resampled dataset COV shape with OVERSAMPLING')\n",
    "print('False:', sum(y_train_ros_cov == False))\n",
    "print('True: ', sum(y_train_ros_cov == True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling - removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus_cov, y_train_rus_cov = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Original dataset shape')\n",
    "print('False:', sum(y_train == False))\n",
    "print('True: ', sum(y_train == True))\n",
    "print('Resampled dataset COV shape with UNDERSAMPLING')\n",
    "print('False:', sum(y_train_rus_cov == False))\n",
    "print('True: ', sum(y_train_rus_cov == True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling (for the COV dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_smote_cov[['Age', 'lead_days']] = scaler.fit_transform(X_train_smote_cov[['Age','lead_days']])\n",
    "X_train_ros_cov[['Age', 'lead_days']] = scaler.fit_transform(X_train_ros_cov[['Age','lead_days']])\n",
    "X_train_rus_cov[['Age', 'lead_days']] = scaler.fit_transform(X_train_rus_cov[['Age','lead_days']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "For this we will use the Mutual Information ML technique, as this has been identified as an appropriate feature selection methods for classification problems in which one has many categorical predictor variables. Using default of n_neighbors = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def identify_features_with_mi_zero(X_train, y_train):\n",
    "    mi = MIC(X_train,y_train, random_state = 42, n_neighbors = 5)\n",
    "    mi = pd.Series(mi)\n",
    "    mi.index = X_train.columns\n",
    "    print(mi.sort_values())\n",
    "    mi = mi.to_frame()\n",
    "    mi.columns = ['MI Score']\n",
    "    mi = mi[mi['MI Score'] != 0]\n",
    "    print(mi.sort_values(by = 'MI Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "identify_features_with_mi_zero(X_train_smote_cov, y_train_smote_cov)\n",
    "identify_features_with_mi_zero(X_train_ros_cov, y_train_ros_cov)\n",
    "identify_features_with_mi_zero(X_train_rus_cov, y_train_rus_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_visulise_confusion_matrix(y_test, y_pred):\n",
    "    '''\n",
    "    Prints a confusion matrix and visualizes the confusion matrix\n",
    "    '''\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"This is the confusion matrix for the initial regression model\")\n",
    "    print(cnf_matrix)\n",
    "    class_names=[0,1]\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def print_classification_report(y_test, y_pred):\n",
    "    '''\n",
    "    Prints classification report based on y_test outputs, real outputs and y_pred outputs\n",
    "    '''\n",
    "    target_names = ['show', 'no-show']\n",
    "    print(\"This is the classification report for the inital regression model.\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, digits = 3))\n",
    "    \n",
    "def run_and_evaluate_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    Runs and evaluates the logistic regression, will output the confusion matrix,\n",
    "    its visualisation, the classification report, the auc plot and apply recursive\n",
    "    feature selection for a given number of features. Hyperparamter tuning included.\n",
    "    '''\n",
    "    log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]} \n",
    "    grid_log_reg = GridSearchCV(LogisticRegression(random_state = 42, max_iter=1000, solver='liblinear'), log_reg_params, cv = 5)\n",
    "    grid_log_reg.fit(X_train, y_train)\n",
    "    logreg = grid_log_reg.best_estimator_\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print_and_visulise_confusion_matrix(y_test, y_pred)\n",
    "    print_classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Oversampled data - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_and_evaluate_logistic_regression(X_train_smote_cov, y_train_smote_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Oversampled data - duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_and_evaluate_logistic_regression(X_train_ros_cov, y_train_ros_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Undersampled data - removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_and_evaluate_logistic_regression(X_train_rus_cov, y_train_rus_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_visualize_confusion_matrix_rf(y_test, y_pred):\n",
    "    '''\n",
    "    Prints a confusion matrix and visualizes the confusion matrix\n",
    "    '''\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"This is the confusion matrix for the random forest model\")\n",
    "    print(cnf_matrix)\n",
    "    class_names=[0,1]\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def run_and_evaluate_random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "    max_depth=[3, 4, 5, 6, 7]\n",
    "    n_estimators = [64, 128, 256]\n",
    "    param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
    "\n",
    "    dfrst = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state = 42)\n",
    "    grid = GridSearchCV(estimator=dfrst, param_grid=param_grid, cv = 5)\n",
    "    grid_results = grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
    "    best_clf = grid_results.best_estimator_\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "    target_names = ['show', 'no-show']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, digits = 3))\n",
    "    print_and_visualize_confusion_matrix_rf(y_test, y_pred)\n",
    "    \n",
    "def feature_importance_for_rfc(X_train, y_train, n_estimators, max_depth):\n",
    "    rfc = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state = 42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    importances = rfc.feature_importances_\n",
    "    columns = X_train.columns\n",
    "    i = 0\n",
    "    co_list = []\n",
    "    fi_list = []\n",
    "    df_fi = pd.DataFrame()\n",
    "    \n",
    "    while i< len(columns):\n",
    "        print(f\"The importance of feature '{columns[i]}' is {round(importances[i]* 100, 2)}%\")\n",
    "        co_list.append(columns[i])\n",
    "        fi_list.append(importances[i])\n",
    "        i +=1\n",
    "    \n",
    "    df_fi['Feature'] = co_list\n",
    "    df_fi['Importance'] = fi_list\n",
    "    return df_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_evaluate_random_forest_classifier(X_train_smote_cov, y_train_smote_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_evaluate_random_forest_classifier(X_train_ros_cov, y_train_ros_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_evaluate_random_forest_classifier(X_train_rus_cov, y_train_rus_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of feature importances after the RF classifiers have been run and the best parameters are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_smote_cov = feature_importance_for_rfc(X_train_smote_cov, y_train_smote_cov, 128, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_ros_cov = feature_importance_for_rfc(X_train_ros_cov, y_train_ros_cov, 128, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_rus_cov = feature_importance_for_rfc(X_train_rus_cov, y_train_rus_cov, 256, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_plot(list1, list2, list3):\n",
    "    lista = list1.merge(list2, on = 'Feature')\n",
    "    final_list = lista.merge(list3, on = 'Feature')\n",
    "    final_list['Average Feature Importance'] = final_list[['Importance_x', 'Importance']].mean(axis=1)\n",
    "    \n",
    "    final_list = final_list.sort_values('Average Feature Importance', ascending = False)\n",
    "    plot = sns.barplot(data=final_list, x=\"Average Feature Importance\", y=\"Feature\", orient = 'h', palette=['#72B7A1'])\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_plot(fi_smote_cov, fi_ros_cov, fi_rus_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_visualize_confusion_matrix(y_test, y_pred):\n",
    "    '''\n",
    "    Prints a confusion matrix and visualizes the confusion matrix\n",
    "    '''\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"This is the confusion matrix for the initial support vector machine model\")\n",
    "    print(cnf_matrix)\n",
    "    class_names=[0,1]\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def print_classification_report(y_test, y_pred):\n",
    "    '''\n",
    "    Prints classification report based on y_test outputs, real outputs and predicted outputs\n",
    "    '''\n",
    "    target_names = ['show', 'no-show']\n",
    "    print(\"This is the classification report for the inital support vector machine model.\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, digits = 3))\n",
    "\n",
    "def run_and_evaluate_support_vector_machine(X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    Runs and evaluates the support vector machine, will output the confusion matrix,\n",
    "    its visualisation, the classification report, the auc plot and apply recursive\n",
    "    feature selection for a given number of features.\n",
    "    \n",
    "    Dual = false because n_samples > n_features and this would otherwise require\n",
    "    the computation of an n_samples x n_samples matrix\n",
    "    '''\n",
    "    param_grid_svc = {'C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    linear_svc = LinearSVC(dual = False, \n",
    "                       max_iter = 1000, \n",
    "                       random_state = 42)\n",
    "    grid = GridSearchCV(linear_svc, param_grid_svc, refit = True, cv = 5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(grid.best_params_, grid.best_estimator_)\n",
    "    grid_predict = grid.predict(X_test)\n",
    "    print_and_visualize_confusion_matrix(y_test, grid_predict)\n",
    "    print_classification_report(y_test, grid_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_and_evaluate_support_vector_machine(X_train_smote_cov, y_train_smote_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_and_evaluate_support_vector_machine(X_train_ros_cov, y_train_ros_cov, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_and_evaluate_support_vector_machine(X_train_rus_cov, y_train_rus_cov, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "84c753e2fedba8b4064398cf9e92860d69d0c9c3010ca85a8ea6175230e9ccf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
